import socket
import threading
import json
import hashlib
import time
import os
from collections import defaultdict

class P2PNode:
    def __init__(self, host='localhost', port=5000):
        self.host = host
        self.port = port
        self.peers = set()  # Ù„ÛŒØ³Øª Ù‡Ù…ØªØ§ÛŒØ§Ù†
        self.chunks = {}  # {chunk_hash: data}
        self.chunk_locations = defaultdict(set)  # {chunk_hash: {peer_addresses}}
        self.running = False
        self.socket = None
        
    def start(self):
        """Ø´Ø±ÙˆØ¹ Node"""
        self.running = True
        self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        self.socket.bind((self.host, self.port))
        self.socket.listen(5)
        
        print(f"ğŸŸ¢ Node Ø´Ø±ÙˆØ¹ Ø´Ø¯: {self.host}:{self.port}")
        
        # Thread Ø¨Ø±Ø§ÛŒ Ú¯ÙˆØ´ Ø¯Ø§Ø¯Ù† Ø¨Ù‡ Ø§ØªØµØ§Ù„Ø§Øª Ø¬Ø¯ÛŒØ¯
        listener_thread = threading.Thread(target=self._listen_for_connections)
        listener_thread.daemon = True
        listener_thread.start()
        
        # Thread Ø¨Ø±Ø§ÛŒ Ú©Ø´Ù NodeÙ‡Ø§ÛŒ Ø¯ÛŒÚ¯Ø±
        discovery_thread = threading.Thread(target=self._discover_peers)
        discovery_thread.daemon = True
        discovery_thread.start()
        
    def _listen_for_connections(self):
        """Ú¯ÙˆØ´ Ø¯Ø§Ø¯Ù† Ø¨Ù‡ Ø§ØªØµØ§Ù„Ø§Øª ÙˆØ±ÙˆØ¯ÛŒ"""
        while self.running:
            try:
                client_socket, address = self.socket.accept()
                thread = threading.Thread(
                    target=self._handle_client,
                    args=(client_socket, address)
                )
                thread.daemon = True
                thread.start()
            except:
                break
                
    def _handle_client(self, client_socket, address):
        """Ù…Ø¯ÛŒØ±ÛŒØª Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØªÛŒ"""
        try:
            data = client_socket.recv(4096).decode('utf-8')
            if not data:
                return
                
            message = json.loads(data)
            response = self._process_message(message)
            
            client_socket.send(json.dumps(response).encode('utf-8'))
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´: {e}")
        finally:
            client_socket.close()
            
    def _process_message(self, message):
        """Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾ÛŒØ§Ù… Ø¯Ø±ÛŒØ§ÙØªÛŒ"""
        msg_type = message.get('type')
        
        if msg_type == 'PEER_DISCOVERY':
            # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† peer Ø¬Ø¯ÛŒØ¯
            peer_addr = message.get('address')
            self.peers.add(peer_addr)
            return {'status': 'ok', 'address': f"{self.host}:{self.port}"}
            
        elif msg_type == 'STORE_CHUNK':
            # Ø°Ø®ÛŒØ±Ù‡ chunk
            chunk_hash = message.get('hash')
            chunk_data = message.get('data')
            self.chunks[chunk_hash] = chunk_data
            print(f"ğŸ’¾ Chunk Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {chunk_hash[:8]}...")
            return {'status': 'stored'}
            
        elif msg_type == 'GET_CHUNK':
            # Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ chunk
            chunk_hash = message.get('hash')
            data = self.chunks.get(chunk_hash)
            return {'status': 'ok', 'data': data}
            
        elif msg_type == 'MAP_TASK':
            # Ø§Ø¬Ø±Ø§ÛŒ task Ù¾Ø±Ø¯Ø§Ø²Ø´ÛŒ
            chunk_hash = message.get('chunk_hash')
            task_type = message.get('task_type')
            chunk_data = self.chunks.get(chunk_hash, '')
            
            result = self._execute_map_task(chunk_data, task_type)
            return {'status': 'ok', 'result': result}
            
        elif msg_type == 'LIST_CHUNKS':
            # Ù„ÛŒØ³Øª chunkÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯
            return {'status': 'ok', 'chunks': list(self.chunks.keys())}
            
        return {'status': 'unknown_command'}
    
    def _execute_map_task(self, data, task_type):
        """Ø§Ø¬Ø±Ø§ÛŒ ÙˆØ¸ÛŒÙÙ‡ Ù¾Ø±Ø¯Ø§Ø²Ø´ÛŒ"""
        if task_type == 'word_count':
            # Ø´Ù…Ø§Ø±Ø´ Ú©Ù„Ù…Ø§Øª
            words = data.split()
            word_count = defaultdict(int)
            for word in words:
                word = word.lower().strip('.,!?;:')
                if word:
                    word_count[word] += 1
            return dict(word_count)
        
        elif task_type == 'line_count':
            # Ø´Ù…Ø§Ø±Ø´ Ø®Ø·ÙˆØ·
            return {'lines': len(data.split('\n'))}
            
        return {}
    
    def _discover_peers(self):
        """Ú©Ø´Ù NodeÙ‡Ø§ÛŒ Ø¯ÛŒÚ¯Ø± Ø¯Ø± Ø´Ø¨Ú©Ù‡"""
        # Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§ Ù…ÛŒâ€ŒØªÙˆÙ†ÛŒØ¯ broadcast UDP ÛŒØ§ Ù„ÛŒØ³Øª Ø«Ø§Ø¨Øª Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯
        # Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø¯Ú¯ÛŒØŒ Ø§Ø² Ù„ÛŒØ³Øª portÙ‡Ø§ÛŒ Ù…Ø´Ø®Øµ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
        base_port = 5000
        for port in range(base_port, base_port + 5):
            if port != self.port:
                peer_addr = f"localhost:{port}"
                try:
                    response = self._send_message(peer_addr, {
                        'type': 'PEER_DISCOVERY',
                        'address': f"{self.host}:{self.port}"
                    })
                    if response and response.get('status') == 'ok':
                        self.peers.add(peer_addr)
                        print(f"ğŸ¤ Peer Ø¬Ø¯ÛŒØ¯ Ù¾ÛŒØ¯Ø§ Ø´Ø¯: {peer_addr}")
                except:
                    pass
        
    def _send_message(self, peer_addr, message, timeout=2):
        """Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… Ø¨Ù‡ peer Ø¯ÛŒÚ¯Ø±"""
        try:
            host, port = peer_addr.split(':')
            port = int(port)
            
            client = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            client.settimeout(timeout)
            client.connect((host, port))
            
            client.send(json.dumps(message).encode('utf-8'))
            response = client.recv(4096).decode('utf-8')
            client.close()
            
            return json.loads(response)
        except Exception as e:
            return None
    
    def split_and_store(self, data, chunk_size=100):
        """ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡ Ø¨Ù‡ chunkÙ‡Ø§ Ùˆ Ø°Ø®ÛŒØ±Ù‡ ØªÙˆØ²ÛŒØ¹â€ŒØ´Ø¯Ù‡"""
        chunks = []
        for i in range(0, len(data), chunk_size):
            chunk = data[i:i+chunk_size]
            chunk_hash = hashlib.md5(chunk.encode()).hexdigest()
            chunks.append((chunk_hash, chunk))
        
        # Ø°Ø®ÛŒØ±Ù‡ Ù…Ø­Ù„ÛŒ
        for chunk_hash, chunk_data in chunks:
            self.chunks[chunk_hash] = chunk_data
        
        # ØªÙˆØ²ÛŒØ¹ Ø¨ÛŒÙ† peerÙ‡Ø§
        peer_list = list(self.peers)
        for idx, (chunk_hash, chunk_data) in enumerate(chunks):
            if peer_list:
                # Ø§Ù†ØªØ®Ø§Ø¨ peer Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡
                peer = peer_list[idx % len(peer_list)]
                response = self._send_message(peer, {
                    'type': 'STORE_CHUNK',
                    'hash': chunk_hash,
                    'data': chunk_data
                })
                if response and response.get('status') == 'stored':
                    self.chunk_locations[chunk_hash].add(peer)
        
        print(f"ğŸ“¦ {len(chunks)} chunk Ø§ÛŒØ¬Ø§Ø¯ Ùˆ ØªÙˆØ²ÛŒØ¹ Ø´Ø¯")
        return [h for h, _ in chunks]
    
    def map_reduce(self, chunk_hashes, task_type='word_count'):
        """Ø§Ø¬Ø±Ø§ÛŒ MapReduce Ø±ÙˆÛŒ chunkÙ‡Ø§"""
        results = []
        
        # Map Phase
        print("ğŸ—ºï¸  Map Phase Ø´Ø±ÙˆØ¹ Ø´Ø¯...")
        for chunk_hash in chunk_hashes:
            # Ø§Ú¯Ø± chunk Ù…Ø­Ù„ÛŒ Ø¯Ø§Ø±ÛŒÙ…
            if chunk_hash in self.chunks:
                result = self._execute_map_task(self.chunks[chunk_hash], task_type)
                results.append(result)
            # Ø§Ú¯Ø± Ù†Ù‡ØŒ Ø§Ø² peer Ø¯ÛŒÚ¯Ø± Ø¨Ú¯ÛŒØ±ÛŒÙ…
            elif chunk_hash in self.chunk_locations:
                peers = list(self.chunk_locations[chunk_hash])
                for peer in peers:
                    response = self._send_message(peer, {
                        'type': 'MAP_TASK',
                        'chunk_hash': chunk_hash,
                        'task_type': task_type
                    })
                    if response and response.get('status') == 'ok':
                        results.append(response['result'])
                        break
        
        # Reduce Phase
        print("ğŸ”„ Reduce Phase Ø´Ø±ÙˆØ¹ Ø´Ø¯...")
        final_result = defaultdict(int)
        for result in results:
            for key, value in result.items():
                final_result[key] += value
        
        return dict(final_result)
    
    def stop(self):
        """ØªÙˆÙ‚Ù Node"""
        self.running = False
        if self.socket:
            self.socket.close()
        print("ğŸ”´ Node Ù…ØªÙˆÙ‚Ù Ø´Ø¯")


# Ù…Ø«Ø§Ù„ Ø§Ø³ØªÙØ§Ø¯Ù‡
if __name__ == "__main__":
    # Ø´Ø±ÙˆØ¹ Node
    node = P2PNode(port=5000)
    node.start()
    
    time.sleep(2)  # Ø²Ù…Ø§Ù† Ø¨Ø±Ø§ÛŒ Ú©Ø´Ù peerÙ‡Ø§
    
    # Ù…Ø«Ø§Ù„: ØªÙ‚Ø³ÛŒÙ… Ùˆ Ø°Ø®ÛŒØ±Ù‡ ÛŒÚ© Ù…ØªÙ†
    sample_text = """
    Ø³Ù„Ø§Ù… Ø§ÛŒÙ† ÛŒÚ© Ù…ØªÙ† Ù†Ù…ÙˆÙ†Ù‡ Ø§Ø³Øª Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ø³ÛŒØ³ØªÙ… ØªÙˆØ²ÛŒØ¹ Ø´Ø¯Ù‡
    Ø§ÛŒÙ† Ø³ÛŒØ³ØªÙ… Ù‚Ø§Ø¯Ø± Ø§Ø³Øª Ø¯Ø§Ø¯Ù‡ Ù‡Ø§ Ø±Ø§ ØªÙ‚Ø³ÛŒÙ… Ú©Ù†Ø¯
    Ùˆ Ø¢Ù†Ù‡Ø§ Ø±Ø§ Ø¨ÛŒÙ† nodeÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù ØªÙˆØ²ÛŒØ¹ Ú©Ù†Ø¯
    Ø³Ù¾Ø³ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÙˆØ§Ø²ÛŒ Ø±Ø§ Ø±ÙˆÛŒ Ø¢Ù†Ù‡Ø§ Ø§Ù†Ø¬Ø§Ù… Ø¯Ù‡Ø¯
    """
    
    print("\nğŸ“ Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´...")
    chunk_hashes = node.split_and_store(sample_text, chunk_size=50)
    
    # Ø§Ø¬Ø±Ø§ÛŒ MapReduce Ø¨Ø±Ø§ÛŒ Ø´Ù…Ø§Ø±Ø´ Ú©Ù„Ù…Ø§Øª
    result = node.map_reduce(chunk_hashes, task_type='word_count')
    
    print("\nğŸ“Š Ù†ØªÛŒØ¬Ù‡ Ø´Ù…Ø§Ø±Ø´ Ú©Ù„Ù…Ø§Øª:")
    for word, count in sorted(result.items(), key=lambda x: x[1], reverse=True):
        print(f"  {word}: {count}")
    
    # Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ† Node Ø¨Ø±Ø§ÛŒ ØªØ³Øª
    input("\nâ¸ï¸  Enter Ø¨Ø²Ù†ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ø®Ø±ÙˆØ¬...")
    node.stop()