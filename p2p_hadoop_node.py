import socket
import threading
import json
import hashlib
import time
import os
from collections import defaultdict
from time import sleep

START_PORT = 5000
END_PORT = 5050

class P2PNode:
    def __init__(self, host='localhost'):
        self.host = host
        self.port = START_PORT
        self.peers = set()  # ip:port
        self.chunks = {}  # {chunk_hash: data}
        self.chunk_locations = defaultdict(set)  # {chunk_hash: {peer_addresses}}
        self.running = False
        self.socket = None
        
    def start(self):
        """Start Node"""
        self.running = True

        self._create_start_listening_socket()

        # Thread Ø¨Ø±Ø§ÛŒ Ú¯ÙˆØ´ Ø¯Ø§Ø¯Ù† Ø¨Ù‡ Ø§ØªØµØ§Ù„Ø§Øª Ø¬Ø¯ÛŒØ¯
        listener_thread = threading.Thread(target=self._listen_for_connections)
        listener_thread.daemon = True
        listener_thread.start()
        
        # Thread Ø¨Ø±Ø§ÛŒ Ú©Ø´Ù NodeÙ‡Ø§ÛŒ Ø¯ÛŒÚ¯Ø±
        discovery_thread = threading.Thread(target=self._discover_peers)
        discovery_thread.daemon = True
        discovery_thread.start()

        self.main_loop()

    def main_loop(self):
        while(self.running):

            command = input("Enter command (h for help):")
            if(command in ["h", 'help']):
                print(
                    """
                    /create-job <file>: creating new job
                    /attach-job <job-serial>: attching to a job
                    """
            )
            sleep(2)

    def _create_start_listening_socket(self):

        while(END_PORT+1 - self.port ):
            try:
                self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
                # self.socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
                self.socket.bind((self.host, self.port))
                self.socket.listen(5)
                print(f"ğŸŸ¢ Node starts on:{self.host}:{self.port}")
                break

            except:
                self.port +=1
            
        else:
            print('âŒ Not available port !')
            self.stop()
        


    def _listen_for_connections(self):
        while self.running:
            try:
                client_socket, address = self.socket.accept()
                thread = threading.Thread(
                    target=self._handle_client,
                    args=(client_socket, address)
                )
                thread.daemon = True
                thread.start()
            except:
                print("Error listening ...")
                self.stop()
                break
                
    def _handle_client(self, client_socket, address):
        try:
            data = client_socket.recv(4096).decode('utf-8')
            if not data:
                return
                
            message = json.loads(data)
            response = self._process_message(message)
            
            client_socket.send(json.dumps(response).encode('utf-8'))
        except Exception as e:
            print(f"âŒ Problem handling client!: {e}")
        finally:
            client_socket.close()
            
    def _process_message(self, message):
        msg_type = message.get('type')
        
        if msg_type == 'PEER_DISCOVERY':
            # adding new peer
            peer_addr = message.get('address')
            self.peers.add(peer_addr)

            print(f"ğŸ¤ New Peer found:{peer_addr}")
            return {'status': 'ok', 'address': f"{self.host}:{self.port}"}
            
        elif msg_type == 'STORE_CHUNK':
            # Ø°Ø®ÛŒØ±Ù‡ chunk
            chunk_hash = message.get('hash')
            chunk_data = message.get('data')
            self.chunks[chunk_hash] = chunk_data
            print(f"ğŸ’¾ Chunk Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {chunk_hash[:8]}...")
            return {'status': 'stored'}
            
        elif msg_type == 'GET_CHUNK':
            # Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ chunk
            chunk_hash = message.get('hash')
            data = self.chunks.get(chunk_hash)
            return {'status': 'ok', 'data': data}
            
        elif msg_type == 'MAP_TASK':
            # Ø§Ø¬Ø±Ø§ÛŒ task Ù¾Ø±Ø¯Ø§Ø²Ø´ÛŒ
            chunk_hash = message.get('chunk_hash')
            task_type = message.get('task_type')
            chunk_data = self.chunks.get(chunk_hash, '')
            
            result = self._execute_map_task(chunk_data, task_type)
            return {'status': 'ok', 'result': result}
            
        elif msg_type == 'LIST_CHUNKS':
            # Ù„ÛŒØ³Øª chunkÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯
            return {'status': 'ok', 'chunks': list(self.chunks.keys())}
            
        return {'status': 'unknown_command'}
    
    def _execute_map_task(self, data, task_type):
        """Ø§Ø¬Ø±Ø§ÛŒ ÙˆØ¸ÛŒÙÙ‡ Ù¾Ø±Ø¯Ø§Ø²Ø´ÛŒ"""
        if task_type == 'word_count':
            # Ø´Ù…Ø§Ø±Ø´ Ú©Ù„Ù…Ø§Øª
            words = data.split()
            word_count = defaultdict(int)
            for word in words:
                word = word.lower().strip('.,!?;:')
                if word:
                    word_count[word] += 1
            return dict(word_count)
        
        elif task_type == 'line_count':
            # Ø´Ù…Ø§Ø±Ø´ Ø®Ø·ÙˆØ·
            return {'lines': len(data.split('\n'))}
            
        return {}
    
    def _discover_peers(self):

        while self.running:
            try:
                """Dicover new nodes"""
                for port in range(START_PORT, END_PORT):
                    if port != self.port:
                        peer_addr = f"localhost:{port}"
                        if(peer_addr not in self.peers):
                            try:
                                response = self._send_message(peer_addr, {
                                    'type': 'PEER_DISCOVERY',
                                    'address': f"{self.host}:{self.port}"
                                })
                                if response and response.get('status') == 'ok':
                                    self.peers.add(peer_addr)
                                    print(f"ğŸ¤ New Peer found:{peer_addr}")
                            except:
                                pass
            except:
                print("Error finding node ...")
                break
            finally:
                sleep(2)
        
    def _send_message(self, peer_addr, message, timeout=2):
        """send message to other peers"""
        try:
            host, port = peer_addr.split(':')
            port = int(port)
            
            client = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            client.settimeout(timeout)
            client.connect((host, port))
            
            client.send(json.dumps(message).encode('utf-8'))
            response = client.recv(4096).decode('utf-8')
            client.close()
            
            return json.loads(response)
        except Exception as e:
            return None
    
    def split_and_store(self, data, chunk_size=100):
        """ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡ Ø¨Ù‡ chunkÙ‡Ø§ Ùˆ Ø°Ø®ÛŒØ±Ù‡ ØªÙˆØ²ÛŒØ¹â€ŒØ´Ø¯Ù‡"""
        chunks = []
        for i in range(0, len(data), chunk_size):
            chunk = data[i:i+chunk_size]
            chunk_hash = hashlib.md5(chunk.encode()).hexdigest()
            chunks.append((chunk_hash, chunk))
        
        # Ø°Ø®ÛŒØ±Ù‡ Ù…Ø­Ù„ÛŒ
        for chunk_hash, chunk_data in chunks:
            self.chunks[chunk_hash] = chunk_data
        
        # ØªÙˆØ²ÛŒØ¹ Ø¨ÛŒÙ† peerÙ‡Ø§
        peer_list = list(self.peers)
        for idx, (chunk_hash, chunk_data) in enumerate(chunks):
            if peer_list:
                # Ø§Ù†ØªØ®Ø§Ø¨ peer Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡
                peer = peer_list[idx % len(peer_list)]
                response = self._send_message(peer, {
                    'type': 'STORE_CHUNK',
                    'hash': chunk_hash,
                    'data': chunk_data
                })
                if response and response.get('status') == 'stored':
                    self.chunk_locations[chunk_hash].add(peer)
        
        print(f"ğŸ“¦ {len(chunks)} chunk Ø§ÛŒØ¬Ø§Ø¯ Ùˆ ØªÙˆØ²ÛŒØ¹ Ø´Ø¯")
        return [h for h, _ in chunks]
    
    def map_reduce(self, chunk_hashes, task_type='word_count'):
        """Ø§Ø¬Ø±Ø§ÛŒ MapReduce Ø±ÙˆÛŒ chunkÙ‡Ø§"""
        results = []
        
        # Map Phase
        print("ğŸ—ºï¸  Map Phase Ø´Ø±ÙˆØ¹ Ø´Ø¯...")
        for chunk_hash in chunk_hashes:
            # Ø§Ú¯Ø± chunk Ù…Ø­Ù„ÛŒ Ø¯Ø§Ø±ÛŒÙ…
            if chunk_hash in self.chunks:
                result = self._execute_map_task(self.chunks[chunk_hash], task_type)
                results.append(result)
            # Ø§Ú¯Ø± Ù†Ù‡ØŒ Ø§Ø² peer Ø¯ÛŒÚ¯Ø± Ø¨Ú¯ÛŒØ±ÛŒÙ…
            elif chunk_hash in self.chunk_locations:
                peers = list(self.chunk_locations[chunk_hash])
                for peer in peers:
                    response = self._send_message(peer, {
                        'type': 'MAP_TASK',
                        'chunk_hash': chunk_hash,
                        'task_type': task_type
                    })
                    if response and response.get('status') == 'ok':
                        results.append(response['result'])
                        break
        
        # Reduce Phase
        print("ğŸ”„ Reduce Phase Ø´Ø±ÙˆØ¹ Ø´Ø¯...")
        final_result = defaultdict(int)
        for result in results:
            for key, value in result.items():
                final_result[key] += value
        
        return dict(final_result)
    
    def stop(self):
        """ØªÙˆÙ‚Ù Node"""
        self.running = False
        if self.socket:
            self.socket.close()
        print("ğŸ”´ Node Stoped !")





# Ù…Ø«Ø§Ù„ Ø§Ø³ØªÙØ§Ø¯Ù‡
if __name__ == "__main__":
    # Ø´Ø±ÙˆØ¹ Node
    node = P2PNode()
    node.start()
    
    time.sleep(2)  # Ø²Ù…Ø§Ù† Ø¨Ø±Ø§ÛŒ Ú©Ø´Ù peerÙ‡Ø§
    
    # Ù…Ø«Ø§Ù„: ØªÙ‚Ø³ÛŒÙ… Ùˆ Ø°Ø®ÛŒØ±Ù‡ ÛŒÚ© Ù…ØªÙ†
    sample_text = """
        Lorem ipsum was conceived as filler text, form for for for atted in a certain way to enable the presentation of graphic elements in documents, without the need for fo
    """
    
    # print("\nğŸ“ Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´...")
    # chunk_hashes = node.split_and_store(sample_text, chunk_size=50)
    
    # # Ø§Ø¬Ø±Ø§ÛŒ MapReduce Ø¨Ø±Ø§ÛŒ Ø´Ù…Ø§Ø±Ø´ Ú©Ù„Ù…Ø§Øª
    # result = node.map_reduce(chunk_hashes, task_type='word_count')
    
    # print("\nğŸ“Š Ù†ØªÛŒØ¬Ù‡ Ø´Ù…Ø§Ø±Ø´ Ú©Ù„Ù…Ø§Øª:")
    # for word, count in sorted(result.items(), key=lambda x: x[1], reverse=True):
    #     print(f"  {word}: {count}")
    
    # Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ† Node Ø¨Ø±Ø§ÛŒ ØªØ³Øª
    input("\nâ¸ï¸  Enter for exit ...")
    node.stop()